import pandas as pd
import numpy as np
import os
import glob
from datetime import datetime
import logging
import io
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
# ã€æ–°å¢ã€‘ç»˜å›¾åº“å­—ä½“ç®¡ç†å™¨ï¼Œç”¨äºæ”¯æŒä¸­æ–‡
import matplotlib.font_manager as fm

# --- é…ç½®å‚æ•° (ä¸å˜) ---
FUND_DATA_DIR = 'fund_data'
INDEX_DATA_DIR = 'index_data'
INDEX_REPORT_BASE_NAME = 'quant_strategy_index_report'
INDEX_NAME = 'MarketMonitor_BuySignal_Index' # ç­–ç•¥æŒ‡æ•°åç§°
CSI300_CODE = '000300' 
CSI300_FILENAME = f'{CSI300_CODE}.csv' 
RISK_FREE_RATE_FILENAME = 'risk_free_rate.csv' 

STARTING_NAV = 1000
RISK_FREE_RATE_ANNUAL = 0.03 
TRANSACTION_COST = 0.001  
MAX_MISSING_DAYS = 20 

# é…ç½®æ—¥å¿— (ä¸å˜)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜) ---
def validate_data(df, filepath, required_columns=['date', 'net_value']):
    """éªŒè¯DataFrameçš„åŸºæœ¬å®Œæ•´æ€§å’Œæ•°æ®åˆç†æ€§ã€‚"""
    if not all(col in df.columns for col in required_columns):
        logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: æ–‡ä»¶ {filepath} ç¼ºå°‘å¿…éœ€åˆ—: {required_columns}")
        return False
    
    df['net_value'] = pd.to_numeric(df['net_value'], errors='coerce')
    df.dropna(subset=['net_value'], inplace=True)
    
    if (df['net_value'] <= 0).any():
        logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: æ–‡ä»¶ {filepath} åŒ…å«æ— æ•ˆå‡€å€¼ï¼ˆè´Ÿå€¼æˆ–é›¶ï¼‰")
        return False
        
    return True

def calculate_mdd(nav_series):
    """è®¡ç®—æœ€å¤§å›æ’¤ (Maximum Drawdown)"""
    if nav_series.empty:
        return 0.0
    rolling_max = nav_series.expanding().max()
    drawdown = (nav_series / rolling_max) - 1.0
    return abs(drawdown.min())

def calculate_sharpe_ratio(return_series, index_df, risk_free_rate_series):
    """è®¡ç®—å¹´åŒ–å¤æ™®æ¯”ç‡ï¼Œä½¿ç”¨åŠ¨æ€å¹´åŒ–å› å­å’ŒåŠ¨æ€æ— é£é™©åˆ©ç‡ã€‚"""
    if return_series.empty or len(return_series) < 2:
        return np.nan
    
    daily_returns = return_series.dropna()
    total_trading_days = len(index_df)
    time_span_days = (index_df.index.max() - index_df.index.min()).days
    trading_days_per_year = total_trading_days / (time_span_days / 365.25) if time_span_days > 0 else 252 
        
    aligned_returns = daily_returns.reindex(risk_free_rate_series.index)
    valid_dates = aligned_returns.index.intersection(risk_free_rate_series.index)
    aligned_returns = aligned_returns.loc[valid_dates]
    rfr_aligned = risk_free_rate_series.loc[valid_dates]
    
    excess_returns = aligned_returns - rfr_aligned
    mean_excess_return = excess_returns.mean()
    std_excess_return = excess_returns.std()
    
    if std_excess_return == 0:
        return np.nan 

    return (mean_excess_return / std_excess_return) * np.sqrt(trading_days_per_year)

def calculate_technical_indicators_for_day(df, ma_window):
    """è®¡ç®—å…³é”®æŠ€æœ¯æŒ‡æ ‡ (RSI, MACD, MA) çš„å†å²åºåˆ—ã€‚"""
    if 'net_value' not in df.columns or len(df) < ma_window:
        for col in ['RSI', 'MACD', 'MACD_Signal', 'NAV_MA50', 'Prev_MACD', 'Prev_Signal']:
             df[col] = np.nan
        return df

    # 1. RSI (14 days)
    delta = df['net_value'].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.ewm(com=13, adjust=False, min_periods=14).mean()
    avg_loss = loss.ewm(com=13, adjust=False, min_periods=14).mean()
    rs = avg_gain / avg_loss
    df['RSI'] = 100 - (100 / (1 + rs))

    # 2. MACD (12, 26, 9)
    ema_12 = df['net_value'].ewm(span=12, adjust=False, min_periods=12).mean()
    ema_26 = df['net_value'].ewm(span=26, adjust=False, min_periods=26).mean()
    df['MACD'] = ema_12 - ema_26
    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False, min_periods=9).mean()

    # 3. åŠ¨æ€ç§»åŠ¨å¹³å‡çº¿ (MA)
    df['MA'] = df['net_value'].rolling(window=ma_window, min_periods=ma_window).mean()
    df['NAV_MA50'] = df['net_value'] / df['MA']
    
    # 4. å‰ä¸€æ—¥ä¿¡å· (ç”¨äºé‡‘å‰æ­»å‰åˆ¤æ–­)
    df['Prev_MACD'] = df['MACD'].shift(1)
    df['Prev_Signal'] = df['MACD_Signal'].shift(1)
    
    return df

def generate_action_signal_vectorized(df, rsi_strong_buy, rsi_weak_buy, nav_ma50_strong_sell, nav_ma50_strong_buy_max, rsi_strong_sell_max):
    """
    ã€å®Œå…¨å‘é‡åŒ–ã€‘æ ¹æ®å¤šå› å­å…±æŒ¯é€»è¾‘ç”Ÿæˆè¡ŒåŠ¨ä¿¡å·ã€‚
    """
    signals = pd.Series('æŒæœ‰/è§‚å¯Ÿ', index=df.index)
    is_macd_golden_cross = (df['MACD'] > df['MACD_Signal']) & (df['Prev_MACD'] < df['Prev_Signal'])
    
    # 1. å¼ºå–å‡º/è§„é¿ (æœ€é«˜ä¼˜å…ˆçº§)
    is_strong_sell = (df['NAV_MA50'] < nav_ma50_strong_sell) | (df['RSI'] > rsi_strong_sell_max)
    signals[is_strong_sell] = 'å¼ºå–å‡º/è§„é¿'
    
    # 2. å¼ºä¹°å…¥ (ç¬¬äºŒä¼˜å…ˆçº§)
    strong_buy_combo = (
        (df['RSI'] < rsi_strong_buy) & 
        (df['NAV_MA50'] < nav_ma50_strong_buy_max) & 
        is_macd_golden_cross
    )
    is_super_strong_buy = (df['RSI'] < (rsi_strong_buy - 5)) 
    strong_buy_condition = strong_buy_combo | is_super_strong_buy
    signals[(signals == 'æŒæœ‰/è§‚å¯Ÿ') & strong_buy_condition] = 'å¼ºä¹°å…¥'

    # 3. å¼±ä¹°å…¥ (æœ€ä½ä¼˜å…ˆçº§)
    is_weak_buy_base = (df['RSI'] < rsi_weak_buy) | is_macd_golden_cross
    signals.mask((signals == 'æŒæœ‰/è§‚å¯Ÿ') & is_weak_buy_base, 'å¼±ä¹°å…¥', inplace=True)

    return signals
    
def _calculate_turnover_ratio(prev_holdings_set, new_holdings_set):
    """
    è®¡ç®—å®é™…æ¢ä»“æ¯”ä¾‹ (Total Turnover Ratio)ã€‚
    é‡‡ç”¨ (ä¹°å…¥æƒé‡ + å–å‡ºæƒé‡) çš„æ›´ç²¾ç»†æ¨¡å‹ã€‚
    """
    if not prev_holdings_set and not new_holdings_set:
        return 0.0
    
    sell_count = len(prev_holdings_set - new_holdings_set)
    sell_weight = sell_count / max(len(prev_holdings_set), 1)
    
    buy_count = len(new_holdings_set - prev_holdings_set)
    buy_weight = buy_count / max(len(new_holdings_set), 1)
    
    turnover_ratio = sell_weight + buy_weight
    
    return min(turnover_ratio, 1.0) 

# --- æ ¸å¿ƒæŒ‡æ•°æ„å»ºç±» ---

class IndexBuilder:
    def __init__(self, fund_data_dir=FUND_DATA_DIR, index_data_dir=INDEX_DATA_DIR, index_name=INDEX_NAME, starting_nav=STARTING_NAV,
                 rsi_strong_buy=30, rsi_weak_buy=40, nav_ma50_strong_sell=0.95, nav_ma50_strong_buy_max=1.00, rsi_strong_sell_max=75,
                 ma_window=50): 
        
        self.fund_data_dir = fund_data_dir
        self.index_data_dir = index_data_dir
        self.index_name = index_name
        self.starting_nav = starting_nav
        self.all_data = {}
        self.csi300_data = None
        self.common_dates = None
        
        self.transaction_cost = TRANSACTION_COST 
        
        self.rsi_strong_buy = rsi_strong_buy
        self.rsi_weak_buy = rsi_weak_buy
        self.nav_ma50_strong_sell = nav_ma50_strong_sell
        self.nav_ma50_strong_buy_max = nav_ma50_strong_buy_max
        self.rsi_strong_sell_max = rsi_strong_sell_max
        self.ma_window = ma_window 
        self.max_missing_days = MAX_MISSING_DAYS 
        
        self.default_risk_free_daily = RISK_FREE_RATE_ANNUAL / 252
        self.risk_free_rate_df = self._load_risk_free_rate()

    def _load_risk_free_rate(self):
        """åŠ è½½åŠ¨æ€æ— é£é™©åˆ©ç‡ï¼Œè‹¥ä¸å­˜åœ¨åˆ™è¿”å› Noneï¼Œå¹¶å¢å¼ºé²æ£’æ€§ã€‚"""
        rfr_file = os.path.join(self.index_data_dir, RISK_FREE_RATE_FILENAME)
        if not os.path.exists(rfr_file):
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åŠ¨æ€æ— é£é™©åˆ©ç‡æ–‡ä»¶ '{rfr_file}'ã€‚å°†ä½¿ç”¨å›ºå®šå¹´åŒ– {RISK_FREE_RATE_ANNUAL:.1%}ã€‚")
            return None
        
        try:
            df = pd.read_csv(rfr_file)
            df['date'] = pd.to_datetime(df['date'])
            df.rename(columns={'rate': 'risk_free_rate_daily'}, inplace=True)
            df.dropna(subset=['risk_free_rate_daily', 'date'], inplace=True)
            df = df.sort_values(by='date').set_index('date')
            
            if (df['risk_free_rate_daily'] <= 0).any():
                logger.error(f"âŒ åŠ¨æ€æ— é£é™©åˆ©ç‡æ–‡ä»¶ {rfr_file} åŒ…å«æ— æ•ˆå€¼ï¼ˆè´Ÿå€¼æˆ–é›¶ï¼‰ã€‚ä½¿ç”¨å›ºå®šå€¼ã€‚")
                return None
                
            df['risk_free_rate_daily'] = df['risk_free_rate_daily'] / 252 
            
            logger.info("âœ… åŠ¨æ€æ— é£é™©åˆ©ç‡æ•°æ®åŠ è½½æˆåŠŸã€‚")
            return df['risk_free_rate_daily']
        except Exception as e:
            logger.error(f"âŒ åŠ è½½åŠ¨æ€æ— é£é™©åˆ©ç‡æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None

    def _get_csi300_data(self):
        """åŠ è½½æ²ªæ·±300æŒ‡æ•°æ•°æ®ã€‚"""
        csi300_file = os.path.join(self.index_data_dir, CSI300_FILENAME)
        if not os.path.exists(csi300_file):
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ²ªæ·±300æ•°æ®æ–‡ä»¶ '{csi300_file}'ã€‚æŒ‡æ•°å¯¹æ¯”åŠŸèƒ½å°†è¢«ç¦ç”¨ã€‚")
            return None
        
        try:
            df = pd.read_csv(csi300_file)
            if not validate_data(df.copy(), csi300_file): return None 
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values(by='date').set_index('date')
            return df
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ²ªæ·±300æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None


    def load_and_preprocess_data(self):
        """åŠ è½½æ‰€æœ‰åŸºé‡‘å’ŒåŸºå‡†æŒ‡æ•°æ•°æ®ï¼Œè®¡ç®—æŒ‡æ ‡ï¼Œå¹¶æŸ¥æ‰¾å…¬å…±æ—¥æœŸã€‚"""
        if not os.path.exists(self.fund_data_dir):
            logger.error(f"âŒ åŸºé‡‘æ•°æ®ç›®å½• '{self.fund_data_dir}' ä¸å­˜åœ¨ã€‚")
            return False
            
        self.csi300_data = self._get_csi300_data()
        
        csv_files = glob.glob(os.path.join(self.fund_data_dir, '*.csv'))
        all_dates_indices = []
        if self.csi300_data is not None:
             all_dates_indices.append(self.csi300_data.index)
        
        for filepath in csv_files:
            fund_code = os.path.splitext(os.path.basename(filepath))[0]
            try:
                df = pd.read_csv(filepath)
                df = df.rename(columns={'net_value': 'net_value', 'date': 'date'}) 
                
                if not validate_data(df.copy(), filepath):
                    continue
                    
                df['date'] = pd.to_datetime(df['date'])
                df = df.sort_values(by='date').set_index('date')
                
                # æ£€æŸ¥é•¿æœŸç¼ºå¤±æ•°æ® (åœç‰Œ)
                initial_na_series = pd.read_csv(filepath)['net_value'].isna()
                max_consecutive_na = initial_na_series.rolling(window=self.max_missing_days).sum().max() if len(initial_na_series) >= self.max_missing_days else 0
                missing_ratio = initial_na_series.sum() / len(initial_na_series) if len(initial_na_series) > 0 else 0
                     
                if max_consecutive_na >= self.max_missing_days or missing_ratio > 0.5:
                    logger.warning(f"âš ï¸ åŸºé‡‘ {fund_code} é•¿æœŸç¼ºå¤±æ•°æ®ï¼ˆæœ€å¤§è¿ç¼º {max_consecutive_na} å¤©æˆ–ç¼ºå¤±ç‡ {missing_ratio:.1%}ï¼‰ï¼Œè·³è¿‡å¤„ç†ã€‚")
                    continue
                
                # æ•°æ®ç¼ºå¤±å¤„ç†ï¼šæ’å€¼å’Œå¡«å……
                df['net_value'] = df['net_value'].interpolate(method='linear').ffill().bfill()
                
                # å†å²è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                df = calculate_technical_indicators_for_day(df.copy(), self.ma_window)
                
                self.all_data[fund_code] = df
                all_dates_indices.append(df.index)
            except Exception as e:
                logger.warning(f"âŒ å¤„ç†åŸºé‡‘æ–‡ä»¶ {filepath} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue

        if not self.all_data:
            logger.error("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•åŸºé‡‘æ•°æ®ã€‚")
            return False

        # ç¡®å®šå…¬å…±æ—¥æœŸèŒƒå›´
        full_index = all_dates_indices[0]
        for index in all_dates_indices[1:]:
            full_index = full_index.union(index)
            
        min_start_date = max(df.index.min() for df in self.all_data.values())
        if self.csi300_data is not None:
            min_start_date = max(min_start_date, self.csi300_data.index.min())

        max_end_date = min(df.index.max() for df in self.all_data.values())
        if self.csi300_data is not None:
             max_end_date = min(max_end_date, self.csi300_data.index.max())

        self.common_dates = full_index[
            (full_index >= min_start_date) & 
            (full_index <= max_end_date)
        ].sort_values()
        
        # å‰”é™¤æ— æ³•è®¡ç®—æŒ‡æ ‡çš„åˆæœŸæ•°æ® (éœ€è¦ MA çª—å£å¤©æ•°çš„æ•°æ®)
        min_indicator_start_date = self.common_dates.min() + pd.Timedelta(days=self.ma_window)
        self.common_dates = self.common_dates[self.common_dates >= min_indicator_start_date]

        if len(self.common_dates) < self.ma_window:
             logger.error(f"âŒ è­¦å‘Šï¼šå…¬å…±æ•°æ®æ—¥æœŸå°‘äº {self.ma_window} å¤© (æ‰¾åˆ° {len(self.common_dates)} å¤©)ã€‚åœæ­¢æ„å»ºã€‚")
             return False

        self._precalculate_signals_and_returns()
        
        logger.info(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆã€‚å…¬å…±æ—¥æœŸèŒƒå›´: {self.common_dates.min().strftime('%Y-%m-%d')} - {self.common_dates.max().strftime('%Y-%m-%d')}")
        return True

    def _precalculate_signals_and_returns(self):
        """é¢„å…ˆè®¡ç®—æ‰€æœ‰åŸºé‡‘åœ¨æ‰€æœ‰ common_dates ä¸Šçš„è¡ŒåŠ¨ä¿¡å·å’Œæ—¥æ”¶ç›Šç‡ã€‚"""
        signals = {}
        returns = {}
        
        for code, df in self.all_data.items():
            signals[code] = generate_action_signal_vectorized(
                df, 
                self.rsi_strong_buy, 
                self.rsi_weak_buy, 
                self.nav_ma50_strong_sell, 
                self.nav_ma50_strong_buy_max,
                self.rsi_strong_sell_max
            )
            
            returns[code] = df['net_value'].pct_change()

        self.signals_df = pd.DataFrame(signals).reindex(self.common_dates)
        self.returns_df = pd.DataFrame(returns).reindex(self.common_dates)
        
        if self.csi300_data is not None:
            self.csi300_returns = self.csi300_data['net_value'].pct_change().reindex(self.common_dates)
        else:
            self.csi300_returns = pd.Series(0.0, index=self.common_dates)

    def _calculate_turnover_ratio(self, prev_holdings_set, new_holdings_set):
        """
        è®¡ç®—å®é™…æ¢ä»“æ¯”ä¾‹ (Total Turnover Ratio)ã€‚
        é‡‡ç”¨ (ä¹°å…¥æƒé‡ + å–å‡ºæƒé‡) çš„æ›´ç²¾ç»†æ¨¡å‹ã€‚
        """
        if not prev_holdings_set and not new_holdings_set:
            return 0.0
        
        sell_count = len(prev_holdings_set - new_holdings_set)
        sell_weight = sell_count / max(len(prev_holdings_set), 1)
        
        buy_count = len(new_holdings_set - prev_holdings_set)
        buy_weight = buy_count / max(len(new_holdings_set), 1)
        
        turnover_ratio = sell_weight + buy_weight
        
        return min(turnover_ratio, 1.0) 


    def build_index(self):
        """è®¡ç®—ç­–ç•¥æŒ‡æ•°å’ŒåŸºå‡†æŒ‡æ•°çš„æ¯æ—¥å‡€å€¼ (NAV)ï¼Œå¹¶è®°å½•æ¯æ—¥ä¿¡å·æ•°é‡ã€‚"""
        
        index_data = pd.DataFrame(index=self.common_dates)
        index_nav = [self.starting_nav]
        csi300_nav = [self.starting_nav]
        current_holdings = [] 
        
        # å¤„ç†åŠ¨æ€æ— é£é™©åˆ©ç‡
        if self.risk_free_rate_df is not None:
            rfr_series = self.risk_free_rate_df.reindex(self.common_dates).ffill().fillna(self.default_risk_free_daily)
        else:
            rfr_series = pd.Series(self.default_risk_free_daily, index=self.common_dates)
            
        # ä»ç¬¬äºŒä¸ªæ—¥æœŸå¼€å§‹è®¡ç®—æŒ‡æ•°
        for i, date in enumerate(self.common_dates):
            if i == 0:
                index_data.loc[date, 'Strategy_Return'] = 0.0
                index_data.loc[date, 'CSI300_Return'] = 0.0
                index_data.loc[date, 'Signal_Funds_Count'] = 0 # è®°å½•ä¿¡å·æ•°é‡
                index_data.loc[date, 'Turnover_Ratio'] = 0.0
                continue
                
            prev_date = self.common_dates[i-1]
            prev_signals = self.signals_df.loc[prev_date]
            buy_signal_codes = prev_signals[prev_signals.isin(['å¼ºä¹°å…¥', 'å¼±ä¹°å…¥'])].index.tolist()

            strategy_return = 0.0
            daily_rfr = rfr_series.loc[date]
            
            is_rebalance = bool(buy_signal_codes) 
            
            turnover_ratio = 0.0
            prev_holdings_set = set(current_holdings)
            new_holdings_set = set(buy_signal_codes)
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦è®¡ç®—æ¢ä»“å’Œæ‰£é™¤æˆæœ¬
            if is_rebalance or (prev_holdings_set != new_holdings_set):
                
                turnover_ratio = self._calculate_turnover_ratio(prev_holdings_set, new_holdings_set)
                
                current_holdings = buy_signal_codes
                signal_count = len(current_holdings)
                
                holdings_returns = self.returns_df.loc[date, current_holdings].dropna()
                
                if not holdings_returns.empty and len(current_holdings) > 0:
                    strategy_return = holdings_returns.mean()
                else:
                    strategy_return = daily_rfr
                
                strategy_return -= self.transaction_cost * turnover_ratio
                    
            elif current_holdings:
                # ä¿æŒå‰æ—¥çš„æŒä»“ç»„åˆ
                signal_count = len(current_holdings)
                
                holdings_returns = self.returns_df.loc[date, current_holdings].dropna()
                        
                if not holdings_returns.empty and len(current_holdings) > 0:
                    strategy_return = holdings_returns.mean()
                else:
                    strategy_return = daily_rfr
                    
            else:
                # ç©ºä»“
                signal_count = 0
                strategy_return = daily_rfr 

            # åŸºå‡†æŒ‡æ•°è®¡ç®—
            csi300_return = self.csi300_returns.loc[date] if date in self.csi300_returns.index and not pd.isna(self.csi300_returns.loc[date]) else 0.0

            # æ›´æ–° NAV
            prev_strategy_nav = index_nav[-1]
            current_strategy_nav = prev_strategy_nav * (1 + strategy_return)
            index_nav.append(current_strategy_nav)
            
            prev_csi300_nav = csi300_nav[-1]
            current_csi300_nav = prev_csi300_nav * (1 + csi300_return)
            csi300_nav.append(current_csi300_nav)

            # è®°å½•æ•°æ®
            index_data.loc[date, 'Strategy_Return'] = strategy_return
            index_data.loc[date, 'CSI300_Return'] = csi300_return
            index_data.loc[date, 'Signal_Funds_Count'] = signal_count # æ ¸å¿ƒæ•°æ®ï¼šæ¯æ—¥ä¹°å…¥ä¿¡å·åŸºé‡‘æ•°
            index_data.loc[date, 'Turnover_Ratio'] = turnover_ratio

        index_data['Strategy_NAV'] = index_nav
        index_data['CSI300_NAV'] = csi300_nav
        index_data.index.name = 'Date'
        
        strategy_mdd = calculate_mdd(index_data['Strategy_NAV'])
        csi300_mdd = calculate_mdd(index_data['CSI300_NAV'])
        strategy_sharpe = calculate_sharpe_ratio(index_data['Strategy_Return'], index_data, rfr_series)
        csi300_sharpe = calculate_sharpe_ratio(index_data['CSI300_Return'], index_data, rfr_series)

        return index_data, strategy_mdd, csi300_mdd, strategy_sharpe, csi300_sharpe

    def _configure_chinese_font(self):
        """é…ç½®ä¸­æ–‡æ”¯æŒï¼Œä¼˜å…ˆä½¿ç”¨ Noto Sans CJK SC"""
        # å°è¯•æŸ¥æ‰¾ Noto Sans CJK SC æˆ–å…¶ä»–å¸¸ç”¨ä¸­æ–‡å­—ä½“
        font_names = ['Noto Sans CJK SC', 'SimHei', 'Microsoft YaHei', 'DejaVu Sans']
        
        found_font = None
        for font_name in font_names:
            try:
                # æ£€æŸ¥å­—ä½“æ˜¯å¦å¯ç”¨
                fm.findfont(font_name, fallback_to_default=False)
                found_font = font_name
                break
            except:
                continue

        if found_font:
            plt.rcParams['font.sans-serif'] = [found_font]
            plt.rcParams['axes.unicode_minus'] = False # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
        else:
            # å¦‚æœæ˜¯ CI ç¯å¢ƒ (å¦‚ GitHub Actions)ï¼Œå¯èƒ½ä¼šæ‰¾ä¸åˆ°å­—ä½“ï¼Œä½†ä»åº”å°è¯•ä½¿ç”¨é»˜è®¤é…ç½®
            logger.warning("âš ï¸ æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ï¼Œå›¾è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½æ˜¾ç¤ºä¸ºæ–¹å—ã€‚è¯·ç¡®ä¿ç³»ç»Ÿå®‰è£…äº† Noto Sans CJK SC æˆ– SimHeiã€‚")

    # ã€åŸæœ‰åŠŸèƒ½ã€‘ç»˜åˆ¶ç´¯è®¡å‡€å€¼æ›²çº¿å›¾
    def _plot_index_nav(self, index_df, output_path):
        """ç”Ÿæˆå¹¶ä¿å­˜æŒ‡æ•°å‡€å€¼æ›²çº¿å›¾ã€‚"""
        self._configure_chinese_font() # è°ƒç”¨å­—ä½“é…ç½®
        plt.style.use('ggplot') 
        fig, ax = plt.subplots(figsize=(12, 6))

        # ç»˜åˆ¶ç­–ç•¥æŒ‡æ•°
        ax.plot(index_df.index, index_df['Strategy_NAV'], label=self.index_name, color='blue', linewidth=2)
        
        # ç»˜åˆ¶åŸºå‡†æŒ‡æ•° (å¦‚æœå­˜åœ¨)
        if self.csi300_data is not None:
            ax.plot(index_df.index, index_df['CSI300_NAV'], label='æ²ªæ·±300 (åŸºå‡†)', color='red', linestyle='--', linewidth=1.5)
        
        # æ ¼å¼åŒ–æ—¥æœŸè½´
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
        ax.xaxis.set_major_locator(mdates.AutoDateLocator())
        fig.autofmt_xdate(rotation=45)

        # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
        ax.set_title(f'{self.index_name} vs æ²ªæ·±300 å‡€å€¼èµ°åŠ¿ ({index_df.index.min().strftime("%Y-%m-%d")} to {index_df.index.max().strftime("%Y-%m-%d")})', fontsize=14)
        ax.set_xlabel('æ—¥æœŸ', fontsize=12)
        ax.set_ylabel('ç´¯è®¡å‡€å€¼ (åŸºå€¼={})'.format(self.starting_nav), fontsize=12)
        ax.legend(loc='upper left')
        ax.grid(True, linestyle='--', alpha=0.7)
        
        # ä¿å­˜å›¾ç‰‡
        plt.tight_layout()
        os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
        plt.savefig(output_path)
        plt.close(fig)
        logger.info(f"âœ… ç´¯è®¡å‡€å€¼æ›²çº¿å›¾å·²ä¿å­˜åˆ° {output_path}")

    # ã€æ–°å¢åŠŸèƒ½ã€‘ç»˜åˆ¶ä¿¡å·æ•°é‡æŒ‡æ•°å›¾
    def _plot_signal_count(self, index_df, output_path):
        """ç”Ÿæˆå¹¶ä¿å­˜æ¯å¤©æ»¡è¶³ä¹°å…¥ä¿¡å·çš„åŸºé‡‘æ•°é‡çš„ç»Ÿè®¡å›¾ï¼ˆä¿¡å·å¼ºåº¦æŒ‡æ•°ï¼‰ã€‚"""
        
        if 'Signal_Funds_Count' not in index_df.columns:
            logger.error("âŒ æ— æ³•ç»˜åˆ¶ä¿¡å·åŸºé‡‘æ•°é‡å›¾ï¼šç¼ºå°‘ 'Signal_Funds_Count' åˆ—ã€‚")
            return
            
        self._configure_chinese_font() # è°ƒç”¨å­—ä½“é…ç½®
        plt.style.use('ggplot') 
        fig, ax = plt.subplots(figsize=(12, 6))

        # ç»˜åˆ¶æ¯æ—¥æ»¡è¶³ä¹°å…¥ä¿¡å·çš„åŸºé‡‘æ•°é‡
        total_funds_count = len(self.all_data)
        ax.bar(index_df.index, index_df['Signal_Funds_Count'], label='æ¯æ—¥ä¹°å…¥ä¿¡å·åŸºé‡‘æ•°é‡', color='green', alpha=0.7)
        
        # ç»˜åˆ¶æ•°é‡çš„æ»šåŠ¨å¹³å‡çº¿ (20æ—¥å‡å€¼)
        rolling_mean = index_df['Signal_Funds_Count'].rolling(window=20).mean()
        ax.plot(index_df.index, rolling_mean, label='20æ—¥ä¿¡å·å¹³å‡æ•°', color='darkorange', linewidth=2)
        
        # æ·»åŠ æ€»åŸºé‡‘æ•°æ¨ªçº¿ä½œä¸ºå‚è€ƒ
        ax.axhline(y=total_funds_count, color='red', linestyle='--', alpha=0.8, label=f'æ€»åŸºé‡‘æ•°é‡ ({total_funds_count})')
        
        # æ ¼å¼åŒ–æ—¥æœŸè½´
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        ax.xaxis.set_major_locator(mdates.AutoDateLocator())
        fig.autofmt_xdate(rotation=45)

        # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
        ax.set_title(f'é‡åŒ–ç­–ç•¥ä¿¡å·å¼ºåº¦æŒ‡æ•° (Signal Strength Index) - æ¯æ—¥ä¹°å…¥ä¿¡å·åŸºé‡‘æ•°é‡', fontsize=14)
        ax.set_xlabel('æ—¥æœŸ', fontsize=12)
        ax.set_ylabel('åŸºé‡‘æ•°é‡', fontsize=12)
        ax.legend(loc='upper left')
        ax.grid(axis='y', linestyle='--', alpha=0.7)
        
        # ä¿å­˜å›¾ç‰‡
        plt.tight_layout()
        os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
        plt.savefig(output_path)
        plt.close(fig)
        logger.info(f"âœ… ä¿¡å·å¼ºåº¦æŒ‡æ•°å›¾å·²ä¿å­˜åˆ° {output_path}")


    def generate_report(self, index_df, strategy_mdd, csi300_mdd, strategy_sharpe, csi300_sharpe):
        """ç”Ÿæˆ Markdown æŠ¥å‘Šï¼Œå¹¶è°ƒç”¨ç»˜å›¾å‡½æ•°ï¼ˆåŒ…å«ä¸¤ä¸ªå›¾ï¼‰ã€‚"""
        now = datetime.now()
        timestamp_for_filename = now.strftime('%Y%m%d_%H%M%S')
        DIR_NAME = now.strftime('%Y%m')
        os.makedirs(DIR_NAME, exist_ok=True)
        
        REPORT_FILE = os.path.join(DIR_NAME, f"{INDEX_REPORT_BASE_NAME}_{timestamp_for_filename}.md")
        PLOT_NAV_FILE = os.path.join(DIR_NAME, f"{INDEX_REPORT_BASE_NAME}_NAV_{timestamp_for_filename}.png") # å‡€å€¼å›¾è·¯å¾„
        PLOT_COUNT_FILE = os.path.join(DIR_NAME, f"{INDEX_REPORT_BASE_NAME}_COUNT_{timestamp_for_filename}.png") # ä¿¡å·æ•°é‡å›¾è·¯å¾„
        
        # 1. ç”Ÿæˆä¸¤å¼ å›¾ç‰‡å¹¶ä¿å­˜
        self._plot_index_nav(index_df, PLOT_NAV_FILE)
        self._plot_signal_count(index_df, PLOT_COUNT_FILE) 
        
        # 2. ç”Ÿæˆ Markdown æŠ¥å‘Šå†…å®¹
        start_date = index_df.index.min().strftime('%Y-%m-%d')
        end_date = index_df.index.max().strftime('%Y-%m-%d')
        strategy_nav_end = index_df['Strategy_NAV'].iloc[-1]
        csi300_nav_end = index_df['CSI300_NAV'].iloc[-1]
        total_return_strategy = (strategy_nav_end / self.starting_nav) - 1
        total_return_csi300 = (csi300_nav_end / self.starting_nav) - 1
        excess_return = total_return_strategy - total_return_csi300
        
        report = f"# é‡åŒ–ç­–ç•¥æŒ‡æ•°æŠ¥å‘Š - {self.index_name}\n\n"
        report += f"ç”Ÿæˆæ—¥æœŸ: {now.strftime('%Y-%m-%d %H:%M:%S')}\n"
        report += f"æ•°æ®å‘¨æœŸ: {start_date} è‡³ {end_date} (å…± {len(index_df)} ä¸ªäº¤æ˜“æ—¥)\n"
        
        # ã€æ›´æ–°æŠ¥å‘Šã€‘å›¾ç‰‡å¼•ç”¨éƒ¨åˆ†ï¼ŒåŒ…å«ä¸¤ä¸ªå›¾
        report += f"\n## 1. ç­–ç•¥ç´¯è®¡å‡€å€¼èµ°åŠ¿å›¾ (ä¼ ç»ŸæŒ‡æ•°åŠŸèƒ½)\n\n![ç´¯è®¡å‡€å€¼æ›²çº¿å›¾]({os.path.basename(PLOT_NAV_FILE)})\n"
        report += f"\n## 2. ä¿¡å·å¼ºåº¦æŒ‡æ•° (Signal Strength Index - å¸‚åœºæœºä¼šçƒ­åº¦)\n\n![ä¿¡å·åŸºé‡‘æ•°é‡å›¾]({os.path.basename(PLOT_COUNT_FILE)})\n"
        
        report += "### **ç­–ç•¥ä¸æ¨¡å‹æœ€ç»ˆæ”¹è¿›æ€»ç»“ï¼š**\n"
        report += f"- **æ€§èƒ½ä¼˜åŒ–:** ä¿¡å·è®¡ç®—å·²å®Œå…¨é‡‡ç”¨**å‘é‡åŒ–**æ“ä½œï¼Œå¹¶ä¿®å¤äº†æ— é£é™©åˆ©ç‡ `NoneType` é”™è¯¯ã€‚\n"
        report += f"- **ä¿¡å·é€»è¾‘:** é‡‡ç”¨å¤šå› å­å…±æŒ¯ï¼ŒMAçª—å£è°ƒæ•´ä¸º **{self.ma_window}** æ—¥ï¼Œ**ä¿¡å·ä¼˜å…ˆçº§ä¸¥æ ¼åŒ–** (å¼ºå– > å¼ºä¹° > å¼±ä¹°)ã€‚\n"
        report += f"- **äº¤æ˜“æˆæœ¬:** æ¯æ¬¡æ¢ä»“æ‰£é™¤ **{self.transaction_cost * 100:.2f}%** æˆæœ¬ï¼Œå¹¶æ ¹æ®**å®é™…æ¢ä»“æ¯”ä¾‹**ï¼ˆä¹°å…¥æƒé‡+å–å‡ºæƒé‡ï¼‰åŠ¨æ€è°ƒæ•´ã€‚\n"
        report += f"- **æ•°æ®é²æ£’æ€§:** å¢å¼ºäº†æ•°æ®éªŒè¯ï¼Œå¹¶å‰”é™¤äº†æœ‰**è¶…è¿‡ {self.max_missing_days} å¤©è¿ç»­ç¼ºå¤±å‡€å€¼**çš„åŸºé‡‘ã€‚\n"
        report += f"- **æ— é£é™©åˆ©ç‡:** é‡‡ç”¨åŠ¨æ€æ— é£é™©åˆ©ç‡ ({'å·²åŠ è½½åŠ¨æ€æ•°æ®' if self.risk_free_rate_df is not None else 'ä½¿ç”¨å›ºå®šå¹´åŒ– 3.0%'})ã€‚\n"
        
        report += f"## **ç­–ç•¥æŒ‡æ•°è¡¨ç°æ€»ç»“**\n"
        report += f"**æŒ‡æ•°åç§°:** {self.index_name}\n"
        report += f"**èµ·å§‹å‡€å€¼:** {self.starting_nav:.0f}\n"
        
        report += "| æŒ‡æ•° | æœ€ç»ˆå‡€å€¼ | æ€»å›æŠ¥ç‡ | è¶…é¢æ”¶ç›Š | å¤æ™®æ¯”ç‡ | æœ€å¤§å›æ’¤ |\n"
        report += "| :--- | ---: | ---: | :---: | :---: | :---: |\n"
        report += (f"| **{self.index_name}** | **{strategy_nav_end:.4f}** | **{total_return_strategy:.2%}** "
                   f"| **{excess_return:.2%}** | **{strategy_sharpe:.2f}** | **{strategy_mdd:.2%}** |\n")
        report += (f"| **æ²ªæ·±300 (åŸºå‡†)** | {csi300_nav_end:.4f} | {total_return_csi300:.2%} "
                   f"| - | {csi300_sharpe:.2f} | {csi300_mdd:.2%} |\n\n")
        
        report += "## æŒ‡æ•°å‡€å€¼å†å²èµ°åŠ¿ (æœ€æ–° 60 å¤©)\n\n"
        
        display_df = index_df.tail(60).copy()
        display_df['Strategy_NAV'] = display_df['Strategy_NAV'].apply(lambda x: f"{x:.4f}")
        display_df['CSI300_NAV'] = display_df['CSI300_NAV'].apply(lambda x: f"{x:.4f}")
        display_df['Signal_Funds_Count'] = display_df['Signal_Funds_Count'].astype(int)
        
        display_df = display_df.rename(columns={
            'Strategy_NAV': 'ç­–ç•¥æŒ‡æ•°å‡€å€¼',
            'CSI300_NAV': 'æ²ªæ·±300å‡€å€¼',
            'Strategy_Return': 'ç­–ç•¥æ—¥æ”¶ç›Š',
            'CSI300_Return': '300æ—¥æ”¶ç›Š',
            'Signal_Funds_Count': 'æŒä»“åŸºé‡‘æ•°',
            'Turnover_Ratio': 'æ¢æ‰‹ç‡'
        })
        
        display_df['ç­–ç•¥æ—¥æ”¶ç›Š'] = display_df['ç­–ç•¥æ—¥æ”¶ç›Š'].apply(lambda x: f"{x * 100:.2%}")
        display_df['300æ—¥æ”¶ç›Š'] = display_df['300æ—¥æ”¶ç›Š'].apply(lambda x: f"{x * 100:.2%}")
        display_df['æ¢æ‰‹ç‡'] = display_df['æ¢æ‰‹ç‡'].apply(lambda x: f"{x * 100:.1f}%")

        markdown_table = display_df[['ç­–ç•¥æŒ‡æ•°å‡€å€¼', 'æ²ªæ·±300å‡€å€¼', 'ç­–ç•¥æ—¥æ”¶ç›Š', '300æ—¥æ”¶ç›Š', 'æŒä»“åŸºé‡‘æ•°', 'æ¢æ‰‹ç‡']].to_markdown(index=True)
        
        with open(REPORT_FILE, 'w', encoding='utf-8') as f:
            f.write(report)
            f.write(markdown_table)

        logger.info(f"âœ… æŒ‡æ•°æŠ¥å‘Šå·²ä¿å­˜åˆ° {REPORT_FILE}")
        return REPORT_FILE

    def run(self):
        """ä¸»æ‰§è¡Œæµç¨‹ã€‚"""
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œé‡åŒ–ç­–ç•¥æŒ‡æ•°æ„å»º...")
            
        if not self.load_and_preprocess_data():
            logger.warning("ğŸš« æ•°æ®åŠ è½½å¤±è´¥æˆ–æ•°æ®é‡ä¸è¶³ï¼Œåœæ­¢æŒ‡æ•°æ„å»ºã€‚")
            return None
        
        result = self.build_index()
        
        if result is not None:
            index_df, strategy_mdd, csi300_mdd, strategy_sharpe, csi300_sharpe = result
            self.generate_report(index_df, strategy_mdd, csi300_mdd, strategy_sharpe, csi300_sharpe)


if __name__ == '__main__':
    # ç¡®ä¿åœ¨è¿è¡Œå‰ï¼Œæ‚¨çš„ fund_data/ å’Œ index_data/ ç›®å½•ä¸‹æœ‰åŸºé‡‘å‡€å€¼æ–‡ä»¶å’Œ 000300.csv ç­‰æ–‡ä»¶
    builder = IndexBuilder()
    builder.run()
